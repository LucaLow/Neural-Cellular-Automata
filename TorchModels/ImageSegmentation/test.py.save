import os
import torch
from torchvision.datasets import ImageFolder
from torchvision.transforms import ToTensor, Compose, Resize
from torch.utils.data import random_split, DataLoader, Dataset
import torch.nn as nn
from model import NCA
from torchvision import datasets, transforms
from PIL import Image
import matplotlib.pyplot as plt
import numpy as np
import random

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")


# Custom Dataset Class
class CustomDataset(Dataset):
    def __init__(self, images_folder, trimaps_folder, transform=None):
        self.images_folder = images_folder
        self.trimaps_folder = trimaps_folder
        self.transform = transform
        self.images = sorted(os.listdir(images_folder))
        self.trimaps = sorted(os.listdir(trimaps_folder))

    def __len__(self):
        return len(self.images)

    def __getitem__(self, idx):
        img_path = os.path.join(self.images_folder, self.images[idx])
        trimap_path = os.path.join(self.trimaps_folder, self.trimaps[idx])
        image = Image.open(img_path).convert("RGB")
        trimap = Image.open(trimap_path).convert("RGB")  # Keep trimap in RGB

        if self.transform:
            image = self.transform(image)
            trimap = self.transform(trimap)

        return image, trimap

# Transformations
transform = Compose([
    Resize((128, 128)),  # Resize images and trimaps to 128x128
    ToTensor()
])

# Absolute paths to the folders
images_folder = '/home/labadmin/dev/imagesegment/images'
trimaps_folder = '/home/labadmin/dev/imagesegment/trimaps_colored'

# Instantiate the dataset
dataset = CustomDataset(images_folder, trimaps_folder, transform=transform)

# Split the dataset into training and validation sets
train_size = int(0.8 * len(dataset))
val_size = len(dataset) - train_size
train_dataset, val_dataset = random_split(dataset, [train_size, val_size])

# DataLoader
train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)

# Instantiate model, optimizer, and loss
model = NCA(input_channels=3, state_channels=64, hidden_channels=64, output_channels=3).to(device)
optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)
criterion = nn.MSELoss()

# Train the Model
for epoch in range(4):
    model.train()
    for i, (data, target) in enumerate(train_loader):
	data, target = data.to(device), target.to(device)
        optimizer.zero_grad()
        #output = model(data)
        output = model.forward(data)
        loss = criterion(output, target)
        loss.backward()
        optimizer.step()
        print(f"Epoch {epoch}, Iteration {i}, Loss: {loss.item()}")



        
    #print(f"Epoch {epoch}, Loss: {loss.item()}")

# Save the model weights after training
torch.save(model.state_dict(), 'model_weights_segmenting.pth')
print("Model weights saved.")

# Validate the Model
model.eval()
with torch.no_grad():
    val_loss = 0
    for data, target in val_loader:

        output = model(data)
        loss = criterion(output, target)
        val_loss += loss.item()
    val_loss /= len(val_loader)
    print(f"Validation Loss: {val_loss}")

# Visualize the output for 10 images
model.eval()
with torch.no_grad():
    for i in range(10):
        data, target = val_dataset[i]
        data = data.unsqueeze(0)  # Add batch dimension
        output = model(data)

        # Plot the input image, ground truth, and predicted output
        fig, axes = plt.subplots(1, 3, figsize=(15, 5))
        axes[0].imshow(data[0].permute(1, 2, 0).cpu().numpy())
        axes[0].set_title('Input Image')
        axes[1].imshow(target[0].permute(1, 2, 0).cpu().numpy())
        axes[1].set_title('Ground Truth')
        axes[2].imshow(output[0].permute(1, 2, 0).detach().cpu().numpy())
        axes[2].set_title('Predicted Output')
        plt.show()
